# Fichier : scripts/1_generate_data.py
# Script pour gÃ©nÃ©rer les donnÃ©es synthÃ©tiques
# ==============================================
#
# OBJECTIF PRINCIPAL :
# Ce script gÃ©nÃ¨re des donnÃ©es synthÃ©tiques rÃ©alistes simulant les coupures
# d'Ã©lectricitÃ© Ã  Dakar sur une pÃ©riode dÃ©finie (par dÃ©faut 1 an).
#
# POURQUOI GÃ‰NÃ‰RER DES DONNÃ‰ES SYNTHÃ‰TIQUES ?
# - Pas d'accÃ¨s aux donnÃ©es rÃ©elles de SENELEC (confidentielles)
# - Besoin de donnÃ©es contrÃ´lÃ©es pour tester les modÃ¨les
# - Permet de simuler des patterns rÃ©alistes (saisonnalitÃ©, heures de pointe, etc.)
#
# FONCTIONNALITÃ‰S :
# 1. GÃ©nÃ¨re un dataset CSV avec ~52,000 lignes (1 an, horaire, 6 quartiers)
# 2. Sauvegarde dans data/raw/power_outages.csv
# 3. Optionnel : Importe dans une base de donnÃ©es SQLite
# 4. Affiche des statistiques dÃ©taillÃ©es
#
# DURÃ‰E : ~5 secondes (gÃ©nÃ©ration) + ~10 secondes (import DB si demandÃ©)
#
# UTILISATION :
# python scripts/1_generate_data.py                    # GÃ©nÃ©ration standard
# python scripts/1_generate_data.py --start 2024-01-01 # PÃ©riode personnalisÃ©e
# python scripts/1_generate_data.py --import-db        # GÃ©nÃ©ration + import DB
# python scripts/1_generate_data.py --no-save          # Voir les stats sans sauvegarder

import sys
from pathlib import Path

# === CONFIGURATION DES CHEMINS ===
# Ajouter le dossier parent (racine du projet) au path Python
# Cela permet d'importer les modules depuis src/
project_root = Path(__file__).parent.parent  # Remonte de scripts/ vers racine/
sys.path.append(str(project_root))

import argparse
from src.data_generator import DataGenerator
from src.database import DatabaseManager, import_csv_to_db
from src.config import RAW_DATA_FILE, START_DATE, END_DATE


# ============================================================================
# FONCTION PRINCIPALE
# ============================================================================

def main():
    """
    Fonction principale du script de gÃ©nÃ©ration de donnÃ©es.
    
    WORKFLOW COMPLET :
    1. Parser les arguments de ligne de commande
    2. GÃ©nÃ©rer les donnÃ©es synthÃ©tiques (DataGenerator)
    3. Sauvegarder le CSV (sauf si --no-save)
    4. Optionnel : Importer dans la base de donnÃ©es SQLite
    5. Afficher les statistiques finales
    
    ARGUMENTS ACCEPTÃ‰S :
    --start      : Date de dÃ©but (format YYYY-MM-DD)
    --end        : Date de fin (format YYYY-MM-DD)
    --no-save    : Ne pas sauvegarder le CSV (mode test)
    --import-db  : Importer les donnÃ©es dans la base de donnÃ©es
    --drop-db    : Supprimer la BD existante avant import (âš ï¸ DESTRUCTIF)
    
    EXEMPLES D'UTILISATION :
    
    1. GÃ©nÃ©ration standard (1 an de donnÃ©es) :
       python scripts/1_generate_data.py
    
    2. PÃ©riode personnalisÃ©e (6 mois) :
       python scripts/1_generate_data.py --start 2023-01-01 --end 2023-06-30
    
    3. GÃ©nÃ©ration + import dans la BD :
       python scripts/1_generate_data.py --import-db
    
    4. RÃ©gÃ©nÃ©rer complÃ¨tement la BD (âš ï¸ efface tout) :
       python scripts/1_generate_data.py --import-db --drop-db
    
    5. Test sans sauvegarde (voir les stats uniquement) :
       python scripts/1_generate_data.py --no-save
    
    Returns:
        DataFrame : Les donnÃ©es gÃ©nÃ©rÃ©es (pour tests/dÃ©bogage)
    """
    
    # === Ã‰TAPE 1 : PARSER LES ARGUMENTS ===
    parser = argparse.ArgumentParser(
        description="GÃ©nÃ¨re les donnÃ©es synthÃ©tiques pour Dakar Power Prediction",
        epilog="""
Exemples:
  %(prog)s                              # GÃ©nÃ©ration standard
  %(prog)s --start 2024-01-01           # PÃ©riode personnalisÃ©e
  %(prog)s --import-db                  # GÃ©nÃ©ration + import BD
  %(prog)s --import-db --drop-db        # RÃ©gÃ©nÃ©ration complÃ¨te
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--start', 
        type=str, 
        default=START_DATE,
        help=f"Date de dÃ©but au format YYYY-MM-DD (dÃ©faut: {START_DATE})"
    )
    
    parser.add_argument(
        '--end', 
        type=str, 
        default=END_DATE,
        help=f"Date de fin au format YYYY-MM-DD (dÃ©faut: {END_DATE})"
    )
    
    parser.add_argument(
        '--no-save', 
        action='store_true',
        help="Ne pas sauvegarder le CSV (utile pour tester la gÃ©nÃ©ration)"
    )
    
    parser.add_argument(
        '--import-db', 
        action='store_true',
        help="Importer les donnÃ©es dans la base de donnÃ©es SQLite aprÃ¨s gÃ©nÃ©ration"
    )
    
    parser.add_argument(
        '--drop-db', 
        action='store_true',
        help="âš ï¸ Supprimer et recrÃ©er la BD avant import (DESTRUCTIF!)"
    )
    
    args = parser.parse_args()
    
    # === EN-TÃŠTE DU SCRIPT ===
    print("\n" + "="*70)
    print("ğŸ“Š SCRIPT 1 : GÃ‰NÃ‰RATION DES DONNÃ‰ES SYNTHÃ‰TIQUES")
    print("="*70)
    
    # === Ã‰TAPE 2 : GÃ‰NÃ‰RER LES DONNÃ‰ES ===
    print(f"\nğŸ”„ GÃ©nÃ©ration des donnÃ©es de {args.start} Ã  {args.end}...")
    print(f"   Configuration :")
    print(f"   â€¢ Date dÃ©but : {args.start}")
    print(f"   â€¢ Date fin   : {args.end}")
    print(f"   â€¢ Sauvegarde : {'NON' if args.no_save else 'OUI'}")
    
    # Initialiser le gÃ©nÃ©rateur avec les dates
    generator = DataGenerator(start_date=args.start, end_date=args.end)
    
    # GÃ©nÃ©rer les donnÃ©es (save=True sauf si --no-save)
    df = generator.generate(save=(not args.no_save))
    
    print(f"\nâœ… DonnÃ©es gÃ©nÃ©rÃ©es avec succÃ¨s !")
    print(f"   â€¢ Lignes crÃ©Ã©es : {len(df):,}")
    print(f"   â€¢ MÃ©moire utilisÃ©e : {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    # === Ã‰TAPE 3 : IMPORT DANS LA BASE DE DONNÃ‰ES (OPTIONNEL) ===
    if args.import_db:
        print("\n" + "="*70)
        print("ğŸ—„ï¸ IMPORT DANS LA BASE DE DONNÃ‰ES")
        print("="*70)
        
        # Importer la fonction d'initialisation
        from src.database import init_database
        
        # Initialiser la BD (drop_existing=True supprime l'ancienne si --drop-db)
        if args.drop_db:
            print("\nâš ï¸ ATTENTION : Suppression de la base de donnÃ©es existante...")
            confirmation = input("   Confirmer ? (oui/non) : ")
            if confirmation.lower() != 'oui':
                print("   âŒ Import annulÃ©.")
                return df
        
        db = init_database(drop_existing=args.drop_db)
        
        if db:
            # VÃ©rifier que le fichier CSV existe bien
            if RAW_DATA_FILE.exists():
                print(f"\nğŸ“ Import du fichier : {RAW_DATA_FILE}")
                
                # Importer le CSV dans la BD
                # Cette fonction lit le CSV ligne par ligne et insÃ¨re dans SQLite
                count = import_csv_to_db(RAW_DATA_FILE, db)
                
                if count > 0:
                    print(f"   âœ… {count:,} enregistrements importÃ©s")
                    
                    # === AFFICHER LES STATISTIQUES DE LA BD ===
                    print("\nğŸ“Š Statistiques de la base de donnÃ©es :")
                    stats = db.get_statistics()
                    
                    # Formater l'affichage des statistiques
                    for key, value in stats.items():
                        # Formater les nombres avec sÃ©parateurs de milliers
                        if isinstance(value, (int, float)):
                            if isinstance(value, float):
                                print(f"   â€¢ {key}: {value:.2f}")
                            else:
                                print(f"   â€¢ {key}: {value:,}")
                        else:
                            print(f"   â€¢ {key}: {value}")
                else:
                    print(f"   âš ï¸ Aucun enregistrement importÃ© (fichier vide ?)")
                
                # Fermer la connexion Ã  la BD proprement
                db.close()
                print("\nâœ… Connexion Ã  la base de donnÃ©es fermÃ©e")
            else:
                print(f"\nâŒ ERREUR : Fichier non trouvÃ© : {RAW_DATA_FILE}")
                print("   ğŸ’¡ Relancez le script sans --no-save pour gÃ©nÃ©rer le CSV d'abord")
        else:
            print("\nâŒ ERREUR : Impossible d'initialiser la base de donnÃ©es")
    
    # === Ã‰TAPE 4 : AFFICHER LE RÃ‰SUMÃ‰ FINAL ===
    print("\n" + "="*70)
    print("âœ… SCRIPT TERMINÃ‰ AVEC SUCCÃˆS")
    print("="*70)
    
    # RÃ©sumÃ© des fichiers gÃ©nÃ©rÃ©s
    print(f"\nğŸ“ FICHIERS GÃ‰NÃ‰RÃ‰S :")
    if not args.no_save:
        print(f"   â€¢ CSV brut : {RAW_DATA_FILE}")
        print(f"     Taille : {RAW_DATA_FILE.stat().st_size / 1024**2:.2f} MB")
    else:
        print(f"   â€¢ Aucun fichier (mode --no-save)")
    
    if args.import_db:
        db_file = project_root / "data" / "power_outages.db"
        if db_file.exists():
            print(f"   â€¢ Base de donnÃ©es : {db_file}")
            print(f"     Taille : {db_file.stat().st_size / 1024**2:.2f} MB")
    
    # Statistiques du DataFrame
    print(f"\nğŸ“Š STATISTIQUES DES DONNÃ‰ES :")
    print(f"   â€¢ Nombre total d'enregistrements : {len(df):,}")
    print(f"   â€¢ Nombre de quartiers            : {df['quartier'].nunique()}")
    print(f"   â€¢ PÃ©riode couverte               : {df['date_heure'].min()} â†’ {df['date_heure'].max()}")
    print(f"   â€¢ Taux global de coupures        : {df['coupure'].mean()*100:.2f}%")
    
    # RÃ©partition par quartier
    print(f"\nğŸ˜ï¸ RÃ‰PARTITION PAR QUARTIER :")
    quartier_stats = df.groupby('quartier')['coupure'].agg(['count', 'mean'])
    quartier_stats.columns = ['Nb observations', 'Taux coupures']
    quartier_stats['Taux coupures'] = quartier_stats['Taux coupures'] * 100
    
    for quartier, row in quartier_stats.iterrows():
        print(f"   â€¢ {quartier:20s} : {row['Nb observations']:6,} obs, {row['Taux coupures']:5.2f}% coupures")
    
    # Avertissement si pas de sauvegarde
    if args.no_save:
        print(f"\nâš ï¸ ATTENTION : DonnÃ©es non sauvegardÃ©es (--no-save)")
        print(f"   Pour sauvegarder, relancez sans l'option --no-save")
    
    return df


# ============================================================================
# POINT D'ENTRÃ‰E DU SCRIPT
# ============================================================================

if __name__ == "__main__":
    """
    Point d'entrÃ©e quand on exÃ©cute : python scripts/1_generate_data.py
    
    Ce script est le PREMIER Ã  exÃ©cuter dans le pipeline du projet.
    Sans donnÃ©es, les autres scripts (preprocess, train, evaluate) ne peuvent pas fonctionner.
    
    ORDRE D'EXÃ‰CUTION DU PROJET :
    1. ğŸ”µ python scripts/1_generate_data.py       â† VOUS ÃŠTES ICI
    2. ğŸŸ¢ python scripts/2_train_models.py
    3. ğŸŸ¡ python scripts/3_evaluate_models.py
    4. ğŸŸ  python scripts/4_deploy_api.py (ou app.py)
    
    STRUCTURE DES DONNÃ‰ES GÃ‰NÃ‰RÃ‰ES :
    Le CSV gÃ©nÃ©rÃ© contient ces colonnes :
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Colonne   â”‚     Type     â”‚           Description               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ date_heure  â”‚ datetime     â”‚ Timestamp (horaire)                 â”‚
    â”‚ quartier    â”‚ str          â”‚ Nom du quartier (6 quartiers)       â”‚
    â”‚ temperature â”‚ float        â”‚ TempÃ©rature en Â°C (25-40Â°C)         â”‚
    â”‚ humidite    â”‚ float        â”‚ HumiditÃ© en % (30-95%)              â”‚
    â”‚ vitesse_ventâ”‚ float        â”‚ Vitesse du vent en km/h (0-50)      â”‚
    â”‚ pluie       â”‚ int          â”‚ Pluie ? (0=non, 1=oui)              â”‚
    â”‚ jour_semaineâ”‚ int          â”‚ Jour de la semaine (0=lun, 6=dim)   â”‚
    â”‚ heure       â”‚ int          â”‚ Heure de la journÃ©e (0-23)          â”‚
    â”‚ mois        â”‚ int          â”‚ Mois (1-12)                         â”‚
    â”‚ coupure     â”‚ int          â”‚ Coupure ? (0=non, 1=oui) â† CIBLE   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    PATTERNS SIMULÃ‰S DANS LES DONNÃ‰ES :
    1. SaisonnalitÃ© :
       - Plus de coupures en saison chaude (avril-juin)
       - Moins de coupures en saison fraÃ®che (dÃ©cembre-fÃ©vrier)
    
    2. Heures de pointe :
       - Pics de coupures : 13h-15h et 20h-22h
       - Creux : 3h-5h (nuit)
    
    3. DiffÃ©rences entre quartiers :
       - Quartiers populaires (GuÃ©diawaye, Pikine) : Plus de coupures
       - Quartiers rÃ©sidentiels (Plateau, Almadies) : Moins de coupures
    
    4. Influence mÃ©tÃ©o :
       - Chaleur extrÃªme â†’ Plus de coupures (climatisation)
       - Pluie â†’ Plus de coupures (court-circuits)
       - Vent fort â†’ Plus de coupures (lignes endommagÃ©es)
    
    TAILLE ATTENDUE DU DATASET :
    - 1 an de donnÃ©es horaires = 365 jours Ã— 24h = 8,760 heures
    - 6 quartiers
    - Total : 8,760 Ã— 6 = 52,560 lignes
    - Taille fichier : ~3-5 MB (CSV)
    
    RÃ‰SOLUTION DES PROBLÃˆMES COURANTS :
    
    âŒ ProblÃ¨me : "ModuleNotFoundError: No module named 'src'"
    âœ… Solution : VÃ©rifiez que vous Ãªtes dans le dossier racine du projet
    
    âŒ ProblÃ¨me : "FileNotFoundError: data/raw/"
    âœ… Solution : Les dossiers sont crÃ©Ã©s automatiquement, mais vÃ©rifiez
                  que vous avez les droits d'Ã©criture
    
    âŒ ProblÃ¨me : "PermissionError" lors de --drop-db
    âœ… Solution : Fermez tout programme qui utilise la BD (DB Browser, etc.)
    
    âŒ ProblÃ¨me : Les donnÃ©es semblent irrÃ©alistes
    âœ… Solution : C'est normal, ce sont des donnÃ©es synthÃ©tiques !
                  Ajustez les paramÃ¨tres dans src/data_generator.py
    """
    main()


# ============================================================================
# NOTES PÃ‰DAGOGIQUES POUR DATA SCIENTIST JUNIOR
# ============================================================================

"""
ğŸ“š CONCEPTS CLÃ‰S Ã€ RETENIR :

1. POURQUOI GÃ‰NÃ‰RER DES DONNÃ‰ES SYNTHÃ‰TIQUES ?
   --------------------------------------------
   En projet rÃ©el, vous auriez accÃ¨s aux vraies donnÃ©es de SENELEC.
   Ici, on simule car :
   - Pas d'accÃ¨s aux donnÃ©es rÃ©elles (confidentielles)
   - Permet de tester le pipeline complet
   - ContrÃ´le total sur les patterns (pour tester les modÃ¨les)
   - ReproductibilitÃ© (mÃªmes donnÃ©es Ã  chaque gÃ©nÃ©ration)

2. STRUCTURE D'UN BON SCRIPT DE GÃ‰NÃ‰RATION
   ----------------------------------------
   âœ… Arguments en ligne de commande (flexibilitÃ©)
   âœ… Validation des paramÃ¨tres (dates, chemins)
   âœ… Messages informatifs (progression, statistiques)
   âœ… Gestion d'erreurs (try/except)
   âœ… Documentation complÃ¨te (ce que vous lisez !)

3. BONNES PRATIQUES - GESTION DES CHEMINS
   ---------------------------------------
   Au lieu de :
     âŒ sys.path.append("../")  # Fragile !
   
   On utilise :
     âœ… Path(__file__).parent.parent  # Robuste !
   
   Pourquoi ? Cela fonctionne peu importe d'oÃ¹ vous lancez le script.

4. ARGUMENTS DE LIGNE DE COMMANDE (argparse)
   ------------------------------------------
   argparse est LA bibliothÃ¨que standard pour parser les arguments.
   
   Types d'arguments :
   - Positionnels : python script.py valeur
   - Optionnels : python script.py --option valeur
   - Flags (boolÃ©ens) : python script.py --flag
   
   Dans notre script :
   - --start, --end : Optionnels avec valeur (dates)
   - --no-save, --import-db : Flags (juste prÃ©sence/absence)

5. SÃ‰PARATION DES RESPONSABILITÃ‰S
   --------------------------------
   Ce script est un "orchestrateur" :
   - Il gÃ¨re les arguments (interface utilisateur)
   - Il appelle DataGenerator (logique mÃ©tier)
   - Il appelle DatabaseManager (persistance)
   
   Principe : "Une fonction = une responsabilitÃ©"
   
   âŒ MAUVAIS : Tout dans main() (15000 lignes)
   âœ… BON : main() orchestre, modules font le travail

6. GESTION DE LA BASE DE DONNÃ‰ES
   ------------------------------
   Option --import-db permet de stocker les donnÃ©es dans SQLite.
   
   Avantages SQLite :
   - Fichier unique (.db)
   - Pas de serveur Ã  lancer
   - SQL standard (apprentissage)
   - IntÃ©gration facile avec Pandas
   
   Quand utiliser --drop-db ?
   - Changement de structure des donnÃ©es
   - Corruption de la BD
   - RÃ©gÃ©nÃ©ration complÃ¨te
   âš ï¸ Attention : Supprime TOUT !

7. STATISTIQUES ET VALIDATION
   ---------------------------
   Toujours afficher des stats aprÃ¨s gÃ©nÃ©ration :
   - Nombre de lignes (vÃ©rifier qu'on a tout)
   - Taux de coupures (cohÃ©rent avec l'attendu ?)
   - RÃ©partition par quartier (Ã©quilibrÃ©e ?)
   - PÃ©riode couverte (dates correctes ?)
   
   Si quelque chose semble bizarre, INVESTIGUER !

8. WORKFLOW TYPIQUE D'UTILISATION
   -------------------------------
   PremiÃ¨re fois (setup complet) :
   1. python scripts/1_generate_data.py --import-db
   
   RÃ©gÃ©nÃ©ration (changement de paramÃ¨tres) :
   2. python scripts/1_generate_data.py --import-db --drop-db
   
   Test rapide (sans sauvegarder) :
   3. python scripts/1_generate_data.py --no-save
   
   PÃ©riode personnalisÃ©e :
   4. python scripts/1_generate_data.py --start 2024-01-01 --end 2024-06-30

9. DÃ‰BOGAGE COURANT
   -----------------
   Si le script plante :
   1. VÃ©rifiez les messages d'erreur (lisez-les vraiment !)
   2. VÃ©rifiez que vous Ãªtes dans le bon dossier (racine du projet)
   3. VÃ©rifiez que les dossiers data/ existent
   4. Essayez avec --no-save d'abord (test sans sauvegarde)
   5. VÃ©rifiez les imports (pip install -r requirements.txt)

10. COMMANDES UTILES
    -----------------
    # GÃ©nÃ©ration standard
    python scripts/1_generate_data.py
    
    # Voir les donnÃ©es gÃ©nÃ©rÃ©es
    head data/raw/power_outages.csv
    
    # Compter les lignes
    wc -l data/raw/power_outages.csv
    
    # VÃ©rifier la taille
    ls -lh data/raw/power_outages.csv
    
    # Ouvrir avec pandas (Python)
    import pandas as pd
    df = pd.read_csv('data/raw/power_outages.csv')
    df.info()
"""
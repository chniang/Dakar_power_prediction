# Fichier : src/database.py
# Gestion de la base de donn√©es (MySQL / SQLite)
# ================================================
#
# Ce fichier g√®re toutes les interactions avec la base de donn√©es.
# Pourquoi une base de donn√©es ? Pour stocker :
# 1. Les donn√©es historiques (52,704 enregistrements)
# 2. Les pr√©dictions effectu√©es par l'application Streamlit
#
# Technologies utilis√©es :
# - SQLAlchemy : ORM (Object-Relational Mapping) Python
#   ‚Üí Permet d'√©crire du code Python au lieu de SQL brut
#   ‚Üí Compatible MySQL et SQLite (m√™me code pour les deux)
#
# Structure :
# 1. Mod√®les ORM (d√©finition des tables)
# 2. Classe DatabaseManager (gestion de la connexion et op√©rations)
# 3. Fonctions utilitaires (initialisation, import CSV)

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import sys
import warnings
warnings.filterwarnings('ignore')

# SQLAlchemy pour la gestion des bases de donn√©es
from sqlalchemy import (
    create_engine, Column, Integer, Float, String, 
    DateTime, Boolean, Text, MetaData, Table, inspect, text
)
from sqlalchemy.orm import sessionmaker, declarative_base
from sqlalchemy.exc import SQLAlchemyError

# Import de la configuration
try:
    from src.config import (
        DATABASE_TYPE, SQLITE_DB_FILE, MYSQL_CONFIG,
        get_db_connection_string, MESSAGES
    )
except ImportError:
    sys.path.append(str(Path(__file__).parent.parent))
    from src.config import (
        DATABASE_TYPE, SQLITE_DB_FILE, MYSQL_CONFIG,
        get_db_connection_string, MESSAGES
    )

# Base pour les mod√®les ORM
# Toutes les classes de tables h√©ritent de cette base
Base = declarative_base()


# ====================================
# 1. MOD√àLES ORM (D√âFINITION DES TABLES)
# ====================================
#
# Les classes ci-dessous d√©finissent la structure des tables SQL.
# SQLAlchemy les convertira automatiquement en commandes CREATE TABLE.

class Enregistrement(Base):
    """
    Table des enregistrements de donn√©es historiques.
    
    Cette table stocke les 52,704 enregistrements g√©n√©r√©s (ou les donn√©es
    r√©elles de SENELEC si disponibles).
    
    Colonnes :
        - id : Identifiant unique auto-incr√©ment√©
        - date_heure : Timestamp de l'enregistrement (index√© pour rapidit√©)
        - quartier : Nom du quartier (index√© pour filtrage rapide)
        - temp_celsius : Temp√©rature en ¬∞C
        - humidite_percent : Humidit√© relative en %
        - vitesse_vent : Vitesse du vent en km/h
        - conso_megawatt : Consommation √©lectrique en MW
        - coupure : Boolean (True=coupure, False=pas de coupure)
        - created_at : Date d'insertion dans la BD
    
    Index cr√©√©s :
        - date_heure : Pour les requ√™tes temporelles (ex: derni√®res 24h)
        - quartier : Pour filtrer par zone g√©ographique
    
    Taille estim√©e : ~10 MB pour 52,704 lignes
    """
    __tablename__ = 'enregistrements'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    date_heure = Column(DateTime, nullable=False, index=True)
    quartier = Column(String(100), nullable=False, index=True)
    temp_celsius = Column(Float, nullable=False)
    humidite_percent = Column(Float, nullable=False)
    vitesse_vent = Column(Float, nullable=False)
    conso_megawatt = Column(Float, nullable=False)
    coupure = Column(Boolean, nullable=False, default=False)
    created_at = Column(DateTime, default=datetime.now)
    
    def __repr__(self):
        """Repr√©sentation textuelle pour le debugging"""
        return f"<Enregistrement(id={self.id}, quartier='{self.quartier}', date='{self.date_heure}')>"


class Prediction(Base):
    """
    Table des pr√©dictions effectu√©es par l'application Streamlit.
    
    Chaque fois qu'un utilisateur fait une pr√©diction dans l'interface,
    on sauvegarde les param√®tres et les r√©sultats ici.
    
    Utilit√© :
        - Audit : Tra√ßabilit√© de toutes les pr√©dictions
        - Analyse : Comparer pr√©dictions vs r√©alit√©
        - Statistiques : Quels quartiers sont les plus consult√©s ?
    
    Colonnes :
        Inputs :
            - date_heure, quartier, temp_celsius, humidite_percent,
              vitesse_vent, conso_megawatt
        
        Outputs :
            - proba_lgbm : Probabilit√© selon LightGBM (0.0-1.0)
            - proba_lstm : Probabilit√© selon LSTM (0.0-1.0)
            - proba_moyenne : Moyenne des deux (0.0-1.0)
            - prediction : D√©cision binaire (0 ou 1)
        
        Metadata :
            - modele_utilise : 'lgbm', 'lstm', ou 'ensemble'
            - seuil_decision : Seuil utilis√© (ex: 0.21)
            - created_at : Timestamp de la pr√©diction
    """
    __tablename__ = 'predictions'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    date_heure = Column(DateTime, nullable=False, index=True)
    quartier = Column(String(100), nullable=False, index=True)
    
    # Conditions d'entr√©e (ce que l'utilisateur a saisi)
    temp_celsius = Column(Float, nullable=False)
    humidite_percent = Column(Float, nullable=False)
    vitesse_vent = Column(Float, nullable=False)
    conso_megawatt = Column(Float, nullable=False)
    
    # Pr√©dictions (r√©sultats des mod√®les)
    proba_lgbm = Column(Float, nullable=False)
    proba_lstm = Column(Float, nullable=False)
    proba_moyenne = Column(Float, nullable=False)
    prediction = Column(Boolean, nullable=False)  # 0 ou 1
    
    # M√©tadonn√©es (pour audit et analyse)
    modele_utilise = Column(String(50), default='ensemble')  # lgbm, lstm, ensemble
    seuil_decision = Column(Float, default=0.5)
    created_at = Column(DateTime, default=datetime.now)
    
    def __repr__(self):
        """Repr√©sentation textuelle pour le debugging"""
        return f"<Prediction(id={self.id}, quartier='{self.quartier}', proba={self.proba_moyenne:.2%})>"


# ====================================
# 2. CLASSE DE GESTION DE LA BASE DE DONN√âES
# ====================================

class DatabaseManager:
    """
    Gestionnaire centralis√© pour toutes les op√©rations sur la base de donn√©es.
    
    Cette classe encapsule :
    - La connexion √† la BD (MySQL ou SQLite)
    - La cr√©ation/suppression de tables
    - L'insertion de donn√©es
    - Les requ√™tes SELECT avec filtres
    - Les statistiques
    
    Avantages de cette approche :
    - Code r√©utilisable (pas de SQL dupliqu√© partout)
    - Gestion d'erreurs centralis√©e
    - Facile √† tester
    - Compatible MySQL ET SQLite (m√™me code)
    
    Exemple d'utilisation :
        db = DatabaseManager()
        db.connect()
        db.create_tables()
        db.insert_raw_data(df)
        stats = db.get_statistics()
        db.close()
    """
    
    def __init__(self, db_type=DATABASE_TYPE):
        """
        Initialise le gestionnaire (sans se connecter encore).
        
        Args:
            db_type (str): Type de BD ('sqlite' ou 'mysql')
                          Par d√©faut, utilise config.DATABASE_TYPE
        
        Note :
            La connexion n'est PAS √©tablie dans __init__ pour √©viter
            les erreurs si la BD n'est pas disponible. On appelle
            explicitement connect() apr√®s.
        """
        self.db_type = db_type
        self.engine = None  # Moteur SQLAlchemy (connexion)
        self.Session = None  # Session factory (pour transactions)
        self.metadata = MetaData()  # M√©tadonn√©es des tables
        
    def connect(self):
        """
        √âtablit la connexion √† la base de donn√©es.
        
        Returns:
            bool: True si succ√®s, False si √©chec
        
        Processus :
            1. R√©cup√©rer la cha√Æne de connexion (depuis config.py)
            2. Cr√©er le moteur SQLAlchemy
            3. Cr√©er la session factory
            4. Tester la connexion avec SELECT 1
        
        Cha√Ænes de connexion :
            SQLite : sqlite:///data/dakar_power.db
            MySQL : mysql+pymysql://user:password@localhost:3306/dakar_predictions
        """
        try:
            # R√©cup√©rer la cha√Æne de connexion depuis config.py
            connection_string = get_db_connection_string()
            print(f"üîó Connexion √† la base de donn√©es ({self.db_type})...")
            
            # Cr√©er le moteur SQLAlchemy
            # echo=False : Pas d'affichage des requ√™tes SQL (mettre True pour debug)
            # pool_pre_ping=True : V√©rifier que la connexion est vivante avant usage
            self.engine = create_engine(
                connection_string,
                echo=False,
                pool_pre_ping=True
            )
            
            # Cr√©er la session factory (pour les transactions ORM)
            self.Session = sessionmaker(bind=self.engine)
            
            # Tester la connexion avec une requ√™te simple
            with self.engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            
            print(f"   ‚úÖ Connexion √©tablie avec succ√®s !")
            return True
            
        except SQLAlchemyError as e:
            # Erreur de connexion (serveur MySQL down, mot de passe incorrect, etc.)
            print(f"   ‚ùå Erreur de connexion : {e}")
            return False
    
    def create_tables(self):
        """
        Cr√©e toutes les tables d√©finies dans les mod√®les ORM.
        
        Returns:
            bool: True si succ√®s, False si √©chec
        
        Cette m√©thode g√©n√®re automatiquement les commandes SQL CREATE TABLE
        √† partir des classes Enregistrement et Prediction.
        
        Si les tables existent d√©j√†, SQLAlchemy ne fait rien (pas d'erreur).
        
        Exemple de SQL g√©n√©r√© pour Enregistrement :
            CREATE TABLE enregistrements (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date_heure DATETIME NOT NULL,
                quartier VARCHAR(100) NOT NULL,
                ...
                INDEX idx_date_heure (date_heure),
                INDEX idx_quartier (quartier)
            );
        """
        try:
            print("üèóÔ∏è Cr√©ation des tables...")
            
            # Cr√©er toutes les tables d√©finies dans Base
            # create_all() g√©n√®re les CREATE TABLE pour chaque classe
            Base.metadata.create_all(self.engine)
            
            # V√©rifier quelles tables ont √©t√© cr√©√©es
            inspector = inspect(self.engine)
            tables = inspector.get_table_names()
            
            print(f"   ‚úÖ Tables cr√©√©es : {', '.join(tables)}")
            return True
            
        except SQLAlchemyError as e:
            print(f"   ‚ùå Erreur lors de la cr√©ation des tables : {e}")
            return False
    
    def drop_tables(self):
        """
        Supprime TOUTES les tables de la base de donn√©es.
        
        ‚ö†Ô∏è ATTENTION : Cette op√©ration est IRR√âVERSIBLE !
        Toutes les donn√©es seront perdues.
        
        Returns:
            bool: True si succ√®s, False si √©chec
        
        Utilisation typique : R√©initialisation compl√®te de la BD
        (par exemple, apr√®s avoir modifi√© la structure des tables)
        """
        try:
            print("‚ö†Ô∏è Suppression de toutes les tables...")
            Base.metadata.drop_all(self.engine)
            print("   ‚úÖ Tables supprim√©es")
            return True
        except SQLAlchemyError as e:
            print(f"   ‚ùå Erreur : {e}")
            return False
    
    def insert_raw_data(self, df):
        """
        Ins√®re les donn√©es brutes (raw_data.csv) dans la table enregistrements.
        
        Args:
            df (pd.DataFrame): DataFrame avec colonnes :
                              date_heure, quartier, temp_celsius, humidite_percent,
                              vitesse_vent, conso_megawatt, coupure
            
        Returns:
            int: Nombre de lignes ins√©r√©es (0 si √©chec)
        
        M√©thode d'insertion :
            pandas.to_sql() avec method='multi' et chunksize=1000
            ‚Üí Insertion par lots de 1000 lignes (rapide et efficace)
        
        Exemple d'utilisation :
            df = pd.read_csv('data/raw/raw_data.csv')
            db.insert_raw_data(df)
        """
        try:
            print(f"üíæ Insertion de {len(df)} enregistrements...")
            
            # Pr√©parer les donn√©es
            df_insert = df.copy()
            df_insert['created_at'] = datetime.now()  # Timestamp d'insertion
            
            # Mapping des colonnes (au cas o√π elles auraient des noms diff√©rents)
            column_mapping = {
                'date_heure': 'date_heure',
                'quartier': 'quartier',
                'temp_celsius': 'temp_celsius',
                'humidite_percent': 'humidite_percent',
                'vitesse_vent': 'vitesse_vent',
                'conso_megawatt': 'conso_megawatt',
                'coupure': 'coupure'
            }
            
            # S√©lectionner uniquement les colonnes n√©cessaires
            cols_to_insert = [col for col in column_mapping.keys() if col in df_insert.columns]
            df_to_insert = df_insert[cols_to_insert + ['created_at']]
            
            # Ins√©rer dans la BD avec pandas.to_sql()
            # if_exists='append' : Ajouter aux donn√©es existantes
            # index=False : Ne pas ins√©rer l'index pandas
            # method='multi' : Insertion par lots (rapide)
            # chunksize=1000 : 1000 lignes par batch
            df_to_insert.to_sql(
                'enregistrements',
                self.engine,
                if_exists='append',
                index=False,
                method='multi',
                chunksize=1000
            )
            
            print(f"   ‚úÖ {len(df)} enregistrements ins√©r√©s")
            return len(df)
            
        except SQLAlchemyError as e:
            print(f"   ‚ùå Erreur d'insertion : {e}")
            return 0
    
    def insert_prediction(self, prediction_data):
        """
        Ins√®re UNE pr√©diction dans la table predictions.
        
        Args:
            prediction_data (dict): Dictionnaire contenant :
                - date_heure, quartier
                - temp_celsius, humidite_percent, vitesse_vent, conso_megawatt
                - proba_lgbm, proba_lstm, proba_moyenne, prediction
                - modele_utilise (optionnel), seuil_decision (optionnel)
            
        Returns:
            int: ID de la pr√©diction ins√©r√©e (ou None si √©chec)
        
        Cette m√©thode est appel√©e par l'application Streamlit chaque fois
        qu'un utilisateur fait une pr√©diction.
        
        Exemple d'utilisation (dans Streamlit) :
            pred_data = {
                'date_heure': datetime.now(),
                'quartier': 'Guediawaye',
                'temp_celsius': 35.0,
                'humidite_percent': 70.0,
                'vitesse_vent': 15.0,
                'conso_megawatt': 900.0,
                'proba_lgbm': 0.245,
                'proba_lstm': 0.507,
                'proba_moyenne': 0.376,
                'prediction': 1,
                'modele_utilise': 'ensemble',
                'seuil_decision': 0.21
            }
            pred_id = db.insert_prediction(pred_data)
        """
        try:
            # Cr√©er une session (transaction)
            session = self.Session()
            
            # Cr√©er un objet Prediction (mod√®le ORM)
            prediction = Prediction(
                date_heure=prediction_data['date_heure'],
                quartier=prediction_data['quartier'],
                temp_celsius=prediction_data['temp_celsius'],
                humidite_percent=prediction_data['humidite_percent'],
                vitesse_vent=prediction_data['vitesse_vent'],
                conso_megawatt=prediction_data['conso_megawatt'],
                proba_lgbm=prediction_data['proba_lgbm'],
                proba_lstm=prediction_data['proba_lstm'],
                proba_moyenne=prediction_data['proba_moyenne'],
                prediction=prediction_data['prediction'],
                modele_utilise=prediction_data.get('modele_utilise', 'ensemble'),
                seuil_decision=prediction_data.get('seuil_decision', 0.5)
            )
            
            # Ajouter √† la session et commiter
            session.add(prediction)
            session.commit()
            
            # R√©cup√©rer l'ID auto-g√©n√©r√©
            pred_id = prediction.id
            session.close()
            
            return pred_id
            
        except SQLAlchemyError as e:
            print(f"‚ùå Erreur d'insertion de pr√©diction : {e}")
            session.rollback()  # Annuler la transaction en cas d'erreur
            session.close()
            return None
    
    def get_enregistrements(self, quartier=None, date_debut=None, date_fin=None, limit=1000):
        """
        R√©cup√®re les enregistrements historiques avec filtres optionnels.
        
        Args:
            quartier (str): Filtrer par quartier (ex: 'Guediawaye')
            date_debut (datetime): Date de d√©but (ex: datetime(2024, 11, 1))
            date_fin (datetime): Date de fin
            limit (int): Nombre max de r√©sultats (d√©faut: 1000)
            
        Returns:
            pd.DataFrame: DataFrame avec les enregistrements
        
        Exemples d'utilisation :
            # Toutes les donn√©es de Guediawaye (max 1000)
            df = db.get_enregistrements(quartier='Guediawaye')
            
            # Derni√®res 24h tous quartiers confondus
            df = db.get_enregistrements(
                date_debut=datetime.now() - timedelta(hours=24),
                limit=500
            )
            
            # Novembre 2024 pour Yoff
            df = db.get_enregistrements(
                quartier='Yoff',
                date_debut=datetime(2024, 11, 1),
                date_fin=datetime(2024, 11, 30)
            )
        """
        try:
            # Construction de la requ√™te SQL avec filtres dynamiques
            query = f"SELECT * FROM enregistrements WHERE 1=1"
            
            if quartier:
                query += f" AND quartier = '{quartier}'"
            if date_debut:
                query += f" AND date_heure >= '{date_debut}'"
            if date_fin:
                query += f" AND date_heure <= '{date_fin}'"
            
            # Tri par date d√©croissante (plus r√©cent en premier)
            query += f" ORDER BY date_heure DESC LIMIT {limit}"
            
            # Ex√©cuter la requ√™te et retourner un DataFrame
            df = pd.read_sql(query, self.engine)
            return df
            
        except SQLAlchemyError as e:
            print(f"‚ùå Erreur de r√©cup√©ration : {e}")
            return pd.DataFrame()  # Retourner un DataFrame vide en cas d'erreur
    
    def get_predictions(self, quartier=None, date_debut=None, date_fin=None, limit=100):
        """
        R√©cup√®re les pr√©dictions effectu√©es avec filtres optionnels.
        
        Args:
            quartier (str): Filtrer par quartier
            date_debut (datetime): Date de d√©but
            date_fin (datetime): Date de fin
            limit (int): Nombre max de r√©sultats (d√©faut: 100)
            
        Returns:
            pd.DataFrame: DataFrame avec les pr√©dictions
        
        Utilit√© :
            - Analyser les pr√©dictions pass√©es
            - Comparer pr√©dictions vs r√©alit√© (si on a les vraies coupures)
            - Statistiques sur l'utilisation de l'application
        """
        try:
            query = f"SELECT * FROM predictions WHERE 1=1"
            
            if quartier:
                query += f" AND quartier = '{quartier}'"
            if date_debut:
                query += f" AND date_heure >= '{date_debut}'"
            if date_fin:
                query += f" AND date_heure <= '{date_fin}'"
            
            # Tri par date de cr√©ation (created_at) d√©croissante
            query += f" ORDER BY created_at DESC LIMIT {limit}"
            
            df = pd.read_sql(query, self.engine)
            return df
            
        except SQLAlchemyError as e:
            print(f"‚ùå Erreur de r√©cup√©ration : {e}")
            return pd.DataFrame()
    
    def get_statistics(self):
        """
        R√©cup√®re des statistiques g√©n√©rales sur la base de donn√©es.
        
        Returns:
            dict: Dictionnaire avec les statistiques :
                - total_enregistrements : Nombre total de lignes
                - total_coupures : Nombre total de coupures
                - total_predictions : Nombre de pr√©dictions effectu√©es
                - quartiers : Liste des quartiers
                - periode_debut, periode_fin : P√©riode couverte
        
        Utilit√© :
            - Afficher un dashboard de statistiques
            - V√©rifier que les donn√©es sont bien charg√©es
            - Monitoring de l'application
        """
        try:
            stats = {}
            
            # Nombre total d'enregistrements
            query = "SELECT COUNT(*) as total FROM enregistrements"
            result = pd.read_sql(query, self.engine)
            stats['total_enregistrements'] = int(result['total'].iloc[0])
            
            # Nombre total de coupures
            query = "SELECT COUNT(*) as total FROM enregistrements WHERE coupure = 1"
            result = pd.read_sql(query, self.engine)
            stats['total_coupures'] = int(result['total'].iloc[0])
            
            # Nombre de pr√©dictions effectu√©es
            query = "SELECT COUNT(*) as total FROM predictions"
            result = pd.read_sql(query, self.engine)
            stats['total_predictions'] = int(result['total'].iloc[0])
            
            # Liste des quartiers uniques
            query = "SELECT DISTINCT quartier FROM enregistrements"
            result = pd.read_sql(query, self.engine)
            stats['quartiers'] = result['quartier'].tolist()
            
            # P√©riode couverte par les donn√©es
            query = "SELECT MIN(date_heure) as debut, MAX(date_heure) as fin FROM enregistrements"
            result = pd.read_sql(query, self.engine)
            stats['periode_debut'] = result['debut'].iloc[0]
            stats['periode_fin'] = result['fin'].iloc[0]
            
            return stats
            
        except SQLAlchemyError as e:
            print(f"‚ùå Erreur de r√©cup√©ration des stats : {e}")
            return {}
    
    def close(self):
        """
        Ferme proprement la connexion √† la base de donn√©es.
        
        Lib√®re les ressources (connexions au pool, m√©moire).
        Toujours appeler cette m√©thode √† la fin !
        
        Exemple :
            try:
                db = DatabaseManager()
                db.connect()
                # ... op√©rations ...
            finally:
                db.close()  # M√™me en cas d'erreur
        """
        if self.engine:
            self.engine.dispose()
            print("üîå Connexion ferm√©e")


# ====================================
# 3. FONCTIONS UTILITAIRES
# ====================================

def init_database(drop_existing=False):
    """
    Initialise la base de donn√©es de mani√®re compl√®te.
    
    Args:
        drop_existing (bool): Si True, supprime et recr√©e les tables
                             (‚ö†Ô∏è PERTE DE DONN√âES !)
        
    Returns:
        DatabaseManager: Instance du gestionnaire (ou None si √©chec)
    
    Cette fonction est pratique pour d√©marrer rapidement :
    - Connexion
    - Cr√©ation des tables
    - Gestion d'erreurs
    
    Exemple d'utilisation (dans un script) :
        db = init_database(drop_existing=True)  # Reset complet
        if db:
            import_csv_to_db('data/raw/raw_data.csv', db)
            db.close()
    """
    print("\n" + "="*60)
    print("üóÑÔ∏è INITIALISATION DE LA BASE DE DONN√âES")
    print("="*60 + "\n")
    
    db = DatabaseManager()
    
    # Connexion
    if not db.connect():
        return None
    
    # Supprimer les tables existantes si demand√©
    if drop_existing:
        db.drop_tables()
    
    # Cr√©er les tables
    db.create_tables()
    
    print("\n" + "="*60)
    print("‚úÖ BASE DE DONN√âES INITIALIS√âE")
    print("="*60 + "\n")
    
    return db


def import_csv_to_db(csv_file, db_manager):
    """
    Importe un fichier CSV dans la base de donn√©es.
    
    Args:
        csv_file (Path): Chemin vers raw_data.csv
        db_manager (DatabaseManager): Instance du gestionnaire
        
    Returns:
        int: Nombre de lignes import√©es
    
    Utilisation typique :
        db = init_database()
        count = import_csv_to_db('data/raw/raw_data.csv', db)
        print(f"{count} lignes import√©es")
        db.close()
    """
    print(f"\nüìÇ Import du fichier : {csv_file}")
    
    # Charger le CSV
    df = pd.read_csv(csv_file, parse_dates=['date_heure'])
    print(f"   üìä {len(df)} lignes charg√©es")
    
    # Ins√©rer dans la BD
    count = db_manager.insert_raw_data(df)
    
    return count


# ====================================
# 4. FONCTION DE TEST
# ====================================

def main():
    """
    Fonction de test pour v√©rifier que la BD fonctionne.
    
    Ex√©cut√©e quand on lance : python src/database.py
    
    Teste :
    - Initialisation de la BD
    - Affichage des statistiques
    - Fermeture propre
    """
    # Initialiser la BD (sans supprimer les donn√©es existantes)
    db = init_database(drop_existing=False)
    
    if db:
        # Afficher les statistiques
        print("\nüìä Statistiques de la base de donn√©es :")
        stats = db.get_statistics()
        for key, value in stats.items():
            print(f"   ‚Ä¢ {key}: {value}")
        
        # Fermer la connexion
        db.close()


if __name__ == "__main__":
    main()
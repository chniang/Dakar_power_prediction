"""
Model Training Module with Fixed LightGBM Parameters
=====================================================

OBJECTIF PRINCIPAL :
Ce module entra√Æne un mod√®le LightGBM pour pr√©dire les coupures d'√©lectricit√©.
Il g√®re le pipeline complet : split des donn√©es, SMOTE, entra√Ænement, √©valuation, sauvegarde.

CORRECTIONS V2 (PAR RAPPORT √Ä V1) :
- ‚úÖ Param√®tres LightGBM ajust√©s pour √©viter l'overfitting sur "quartier_encoded"
- ‚úÖ SMOTE "l√©ger" (20% max au lieu de 50/50) pour pr√©server les corr√©lations r√©elles
- ‚úÖ R√©gularisation L1/L2 pour p√©naliser les splits faciles
- ‚úÖ Arbres moins profonds (max_depth=6 au lieu de 10)

ARCHITECTURE :
Ce fichier est une VERSION ALTERNATIVE du script 2_train_models.py
Il utilise une approche orient√©e objet (classe ModelTrainer) au lieu de fonctions.

AVANTAGES DE CETTE APPROCHE :
- Encapsulation : Tout est dans la classe ModelTrainer
- √âtat persistant : metrics, model, feature_names stock√©s
- R√©utilisable : Facile de cr√©er plusieurs instances
- Testable : Chaque m√©thode testable ind√©pendamment

DUR√âE : ~2 minutes (SMOTE + entra√Ænement LightGBM)
"""

import os
import json
import logging
from typing import Dict, Tuple
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix
)
from imblearn.over_sampling import SMOTE

# === CONFIGURATION DU LOGGING ===
# Logging permet de tracer l'ex√©cution sans polluer stdout avec des print()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# CLASSE PRINCIPALE : ModelTrainer
# ============================================================================

class ModelTrainer:
    """
    Entra√Æneur de mod√®le LightGBM avec importance des features √©quilibr√©e.
    
    PHILOSOPHIE DE CONCEPTION :
    Cette classe suit le principe "Single Responsibility" :
    - Elle g√®re UNIQUEMENT l'entra√Ænement du mod√®le LightGBM
    - Pas de pr√©processing (fait par un autre module)
    - Pas de d√©ploiement (fait par un autre module)
    
    PATTERN UTILIS√â : Template Method
    Le workflow d'entra√Ænement est fixe :
    1. prepare_stratified_split() ‚Üí D√©coupe train/test
    2. apply_light_smote() ‚Üí √âquilibre les classes
    3. train() ‚Üí Entra√Æne le mod√®le
    4. evaluate() ‚Üí √âvalue les performances
    5. save() ‚Üí Sauvegarde mod√®le + m√©triques
    
    √âTAT INTERNE (ATTRIBUTS) :
    - model_dir : Dossier de sauvegarde
    - model : Mod√®le LightGBM entra√Æn√©
    - feature_names : Liste des noms de features
    - metrics : Dictionnaire des m√©triques (accuracy, f1, etc.)
    
    EXEMPLE D'UTILISATION :
    ```python
    trainer = ModelTrainer(model_dir='models')
    train_df, test_df = trainer.prepare_stratified_split(df)
    trainer.train(train_df)
    trainer.evaluate(test_df)
    trainer.save()
    ```
    """
    
    def __init__(self, model_dir: str = 'models'):
        """
        Initialise l'entra√Æneur.
        
        Args:
            model_dir : Dossier o√π sauvegarder le mod√®le (d√©faut: 'models/')
        """
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)  # Cr√©er le dossier si inexistant
        
        # √âtat initial
        self.model = None           # Sera rempli apr√®s train()
        self.feature_names = None   # Sera rempli apr√®s train()
        self.metrics = {}           # Sera rempli apr√®s evaluate()
    
    def prepare_stratified_split(
        self, 
        df: pd.DataFrame,
        test_size: float = 0.2
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        D√©coupe les donn√©es en train/test de mani√®re CHRONOLOGIQUE.
        
        POURQUOI CHRONOLOGIQUE (ET PAS AL√âATOIRE) ?
        En s√©ries temporelles, on DOIT respecter l'ordre temporel :
        - Entra√Ænement sur le pass√© (80% des donn√©es)
        - Test sur le futur (20% des donn√©es)
        
        Si on fait un split al√©atoire, on "triche" :
        - Le mod√®le voit des donn√©es du futur pendant l'entra√Ænement
        - Les performances sont artificiellement gonfl√©es
        - En production, le mod√®le sera moins bon
        
        EXEMPLE :
        Donn√©es : Jan ‚Üí D√©c 2023 (12 mois)
        Split 80/20 :
        - Train : Jan ‚Üí Oct (10 mois)
        - Test : Nov ‚Üí D√©c (2 mois)
        
        STRATIFICATION :
        M√™me si le split est chronologique, on v√©rifie que le taux de coupures
        est similaire dans train et test (affichage informatif).
        
        Args:
            df : DataFrame avec colonnes 'date' et 'coupure'
            test_size : Proportion du test set (d√©faut: 0.2 = 20%)
        
        Returns:
            Tuple[train_df, test_df] : Donn√©es d'entra√Ænement et de test
        """
        # Trier par date (garantir l'ordre chronologique)
        df = df.sort_values('date').reset_index(drop=True)
        
        # Calculer l'index de d√©coupe (80% des donn√©es)
        split_idx = int(len(df) * (1 - test_size))
        
        # Split chronologique
        train_df = df.iloc[:split_idx].copy()   # 0 ‚Üí split_idx
        test_df = df.iloc[split_idx:].copy()    # split_idx ‚Üí fin
        
        # Afficher les statistiques du split
        logger.info(f"Train size: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)")
        logger.info(f"Test size: {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)")
        logger.info(f"Train positive rate: {train_df['coupure'].mean()*100:.2f}%")
        logger.info(f"Test positive rate: {test_df['coupure'].mean()*100:.2f}%")
        
        return train_df, test_df
    
    def apply_light_smote(
        self, 
        X: pd.DataFrame, 
        y: pd.Series
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """
        Applique SMOTE "l√©ger" pour r√©duire le d√©s√©quilibre (SANS √©quilibrer compl√®tement).
        
        SMOTE (Synthetic Minority Over-sampling Technique) :
        Algorithme qui cr√©e des donn√©es synth√©tiques de la classe minoritaire.
        
        COMMENT √áA MARCHE ?
        1. Pour chaque √©chantillon minoritaire (coupure=1)
        2. Trouver ses k voisins les plus proches (k=5)
        3. Cr√©er un nouvel √©chantillon entre l'original et un voisin al√©atoire
        4. R√©p√©ter jusqu'√† atteindre le ratio cible
        
        SMOTE "L√âGER" VS "COMPLET" :
        ‚ùå SMOTE complet : 50/50 (autant de 0 que de 1)
        ‚úÖ SMOTE l√©ger : 20% max de 1 (ou 2√ó le ratio original)
        
        POURQUOI "L√âGER" ?
        - Pr√©serve mieux les corr√©lations r√©elles des donn√©es
        - √âvite l'overfitting sur les donn√©es synth√©tiques
        - Plus proche de la distribution r√©elle en production
        
        EXEMPLE :
        Avant SMOTE : 93% classe 0, 7% classe 1 (d√©s√©quilibr√©)
        Apr√®s SMOTE l√©ger : 85% classe 0, 15% classe 1 (moins d√©s√©quilibr√©)
        
        QUAND SMOTE N'EST PAS APPLIQU√â :
        Si le ratio est d√©j√† >= 20%, on ne fait rien (logger.info "No SMOTE needed")
        
        Args:
            X : Features (DataFrame)
            y : Target (Series avec 0 et 1)
        
        Returns:
            Tuple[X_resampled, y_resampled] : Donn√©es r√©√©chantillonn√©es
        """
        # Calculer le ratio original
        original_ratio = y.sum() / len(y)  # Proportion de 1
        
        # Calculer le ratio cible (20% max, ou 2√ó l'original)
        target_ratio = min(0.2, original_ratio * 2)
        
        # Calculer le nombre d'√©chantillons n√©cessaires
        n_minority = y.sum()                    # Nombre de 1
        n_majority = len(y) - n_minority        # Nombre de 0
        target_minority = int(n_majority * target_ratio / (1 - target_ratio))
        
        # V√©rifier si SMOTE est n√©cessaire
        if target_minority <= n_minority:
            logger.info("No SMOTE needed (ratio already good)")
            return X, y
        
        # Initialiser SMOTE
        smote = SMOTE(
            sampling_strategy=target_minority / n_majority,  # Ratio cible
            random_state=42,     # Reproductibilit√©
            k_neighbors=5        # Nombre de voisins (standard)
        )
        
        # Appliquer SMOTE
        X_resampled, y_resampled = smote.fit_resample(X, y)
        
        # Afficher les statistiques
        logger.info(f"Before SMOTE: {y.sum()}/{len(y)} = {original_ratio*100:.2f}%")
        logger.info(f"After SMOTE: {y_resampled.sum()}/{len(y_resampled)} = {y_resampled.mean()*100:.2f}%")
        
        return X_resampled, y_resampled
    
    def train(self, train_df: pd.DataFrame) -> Dict:
        """
        Entra√Æne le mod√®le LightGBM avec param√®tres corrig√©s (V2).
        
        CORRECTIONS V2 PAR RAPPORT √Ä V1 :
        Le probl√®me V1 : Le mod√®le se focalisait trop sur "quartier_encoded"
        ‚Üí Dakar-Plateau pr√©dit comme plus risqu√© que Guediawaye (INVERS√â)
        
        Causes identifi√©es :
        1. SMOTE trop agressif (50/50) ‚Üí m√©langeait les quartiers
        2. Arbres trop profonds (max_depth=10) ‚Üí overfitting facile
        3. Pas de r√©gularisation ‚Üí pas de p√©nalit√© pour splits simples
        
        Solutions V2 :
        ‚úÖ SMOTE l√©ger (20% max) ‚Üí pr√©serve les corr√©lations
        ‚úÖ max_depth=6 (au lieu de 10) ‚Üí arbres moins profonds
        ‚úÖ min_child_samples=50 (au lieu de 20) ‚Üí splits plus robustes
        ‚úÖ reg_alpha=0.1, reg_lambda=0.1 ‚Üí r√©gularisation L1/L2
        ‚úÖ min_split_gain=0.01 ‚Üí √©vite les splits trop faciles
        
        PARAM√àTRES LIGHTGBM EXPLIQU√âS :
        
        - objective='binary' : Classification binaire (0 ou 1)
        - metric='auc' : Optimiser l'aire sous la courbe ROC
        - boosting_type='gbdt' : Gradient Boosting (standard)
        
        - num_leaves=31 : Nombre de feuilles par arbre
          (r√©duit de 60 ‚Üí 31 pour moins d'overfitting)
        
        - max_depth=6 : Profondeur maximale des arbres
          (r√©duit de 10 ‚Üí 6 pour √©viter m√©morisation de "quartier")
        
        - learning_rate=0.05 : Taux d'apprentissage
          (augment√© de 0.03 ‚Üí 0.05 pour convergence plus rapide)
        
        - feature_fraction=0.9 : Proportion de features par arbre (90%)
          (augment√© de 0.8 ‚Üí 0.9 pour utiliser plus d'info)
        
        - bagging_fraction=0.9 : Proportion de donn√©es par arbre (90%)
          (augment√© pour plus de stabilit√©)
        
        - min_child_samples=50 : Min √©chantillons par feuille
          (augment√© de 20 ‚Üí 50 pour √©viter feuilles trop sp√©cifiques)
        
        - min_split_gain=0.01 : Gain minimum pour cr√©er un split
          (nouveau en V2, emp√™che les splits triviaux)
        
        - reg_alpha=0.1 : R√©gularisation L1 (Lasso)
          (nouveau en V2, p√©nalise les poids √©lev√©s)
        
        - reg_lambda=0.1 : R√©gularisation L2 (Ridge)
          (nouveau en V2, lisse les poids)
        
        - scale_pos_weight=2.0 : Poids de la classe positive
          (r√©duit de 10.0 ‚Üí 2.0 car SMOTE a d√©j√† √©quilibr√©)
        
        - n_estimators=500 : Nombre d'arbres
          (r√©duit de 1000 ‚Üí 500, early stopping prendra le relais)
        
        Args:
            train_df : DataFrame d'entra√Ænement avec colonnes features + 'coupure' + 'date'
        
        Returns:
            Dict : M√©triques d'entra√Ænement (feature_importance)
        """
        logger.info("Starting model training...")
        
        # === √âTAPE 1 : S√âPARER FEATURES ET TARGET ===
        # Exclure 'coupure' (target) et 'date' (pas une feature)
        feature_cols = [col for col in train_df.columns 
                       if col not in ['coupure', 'date']]
        
        X_train = train_df[feature_cols]
        y_train = train_df['coupure']
        
        # Sauvegarder les noms de features (pour pr√©dictions futures)
        self.feature_names = feature_cols
        
        # === √âTAPE 2 : APPLIQUER SMOTE L√âGER ===
        X_train_balanced, y_train_balanced = self.apply_light_smote(X_train, y_train)
        
        # === √âTAPE 3 : D√âFINIR LES PARAM√àTRES LIGHTGBM (V2 CORRIG√âS) ===
        params = {
            'objective': 'binary',
            'metric': 'auc',
            'boosting_type': 'gbdt',
            'num_leaves': 31,          # ‚úÖ R√©duit pour √©viter overfitting
            'max_depth': 6,            # ‚úÖ Arbres moins profonds
            'learning_rate': 0.05,     # ‚úÖ Convergence plus rapide
            'feature_fraction': 0.9,   # ‚úÖ Utilise plus de features
            'bagging_fraction': 0.9,   # ‚úÖ Plus de donn√©es par arbre
            'bagging_freq': 5,
            'min_child_samples': 50,   # ‚úÖ Feuilles plus robustes
            'min_split_gain': 0.01,    # ‚úÖ NOUVEAU : √âvite splits triviaux
            'reg_alpha': 0.1,          # ‚úÖ NOUVEAU : R√©gularisation L1
            'reg_lambda': 0.1,         # ‚úÖ NOUVEAU : R√©gularisation L2
            'scale_pos_weight': 2.0,   # Compense le d√©s√©quilibre restant
            'verbose': -1,             # Pas de logs verbeux
            'n_estimators': 500,       # ‚úÖ Moins d'arbres (early stopping)
            'random_state': 42         # Reproductibilit√©
        }
        
        # === √âTAPE 4 : CR√âER LE DATASET LIGHTGBM ===
        train_data = lgb.Dataset(
            X_train_balanced,
            label=y_train_balanced,
            feature_name=feature_cols  # Noms des colonnes (pour importance)
        )
        
        # === √âTAPE 5 : ENTRA√éNER LE MOD√àLE ===
        self.model = lgb.train(
            params,
            train_data,
            valid_sets=[train_data],  # Validation sur train (pour early stopping)
            callbacks=[lgb.early_stopping(stopping_rounds=50)]  # Stop si pas d'am√©lioration
        )
        
        logger.info("Training completed")
        
        # === √âTAPE 6 : CALCULER L'IMPORTANCE DES FEATURES ===
        # importance_type='gain' : Combien chaque feature am√©liore le mod√®le
        importance = self.model.feature_importance(importance_type='gain')
        self.metrics['feature_importance'] = dict(zip(feature_cols, importance.tolist()))
        
        # Afficher le top 5
        logger.info("\n=== TOP 5 FEATURES BY IMPORTANCE ===")
        for feat, imp in sorted(
            self.metrics['feature_importance'].items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:5]:
            logger.info(f"{feat}: {imp:.0f}")
        
        return self.metrics
    
    def evaluate(self, test_df: pd.DataFrame) -> Dict:
        """
        √âvalue le mod√®le sur le test set.
        
        M√âTRIQUES CALCUL√âES :
        1. Accuracy : % de pr√©dictions correctes (attention aux donn√©es d√©s√©quilibr√©es)
        2. Precision : % de vrais positifs parmi les pr√©dictions positives
        3. Recall : % de vrais positifs d√©tect√©s
        4. F1-Score : Moyenne harmonique de Precision et Recall
        5. ROC-AUC : Capacit√© √† discriminer les classes
        6. Confusion Matrix : TN, FP, FN, TP
        
        SEUIL DE D√âCISION :
        On utilise 0.5 par d√©faut (proba >= 0.5 ‚Üí pr√©diction=1)
        En production, on pourrait optimiser ce seuil selon F1-Score.
        
        Args:
            test_df : DataFrame de test avec colonnes features + 'coupure' + 'date'
        
        Returns:
            Dict : Toutes les m√©triques d'√©valuation
        """
        logger.info("Evaluating model on test set...")
        
        # === √âTAPE 1 : PR√âPARER LES DONN√âES ===
        feature_cols = [col for col in test_df.columns 
                       if col not in ['coupure', 'date']]
        X_test = test_df[feature_cols]
        y_test = test_df['coupure']
        
        # === √âTAPE 2 : PR√âDICTIONS ===
        # predict() retourne des probabilit√©s (0.0 √† 1.0)
        y_pred_proba = self.model.predict(X_test)
        
        # Convertir en pr√©dictions binaires (0 ou 1) avec seuil 0.5
        y_pred = (y_pred_proba >= 0.5).astype(int)
        
        # === √âTAPE 3 : CALCULER LES M√âTRIQUES ===
        metrics = {
            'accuracy': float(accuracy_score(y_test, y_pred)),
            'precision': float(precision_score(y_test, y_pred, zero_division=0)),
            'recall': float(recall_score(y_test, y_pred, zero_division=0)),
            'f1': float(f1_score(y_test, y_pred, zero_division=0)),
            'roc_auc': float(roc_auc_score(y_test, y_pred_proba))
        }
        
        # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        metrics['confusion_matrix'] = cm.tolist()
        
        # Sauvegarder dans l'√©tat de la classe
        self.metrics.update(metrics)
        
        # === √âTAPE 4 : AFFICHER LES R√âSULTATS ===
        logger.info(f"\n=== TEST SET METRICS ===")
        logger.info(f"Accuracy  : {metrics['accuracy']:.4f}")
        logger.info(f"Precision : {metrics['precision']:.4f}")
        logger.info(f"Recall    : {metrics['recall']:.4f}")
        logger.info(f"F1-Score  : {metrics['f1']:.4f}")
        logger.info(f"ROC-AUC   : {metrics['roc_auc']:.4f}")
        
        return metrics
    
    def save(self):
        """
        Sauvegarde le mod√®le et les m√©triques.
        
        FICHIERS G√âN√âR√âS :
        1. lightgbm_model.txt : Mod√®le LightGBM (format texte)
        2. metrics.json : Toutes les m√©triques (format JSON)
        
        FORMAT LIGHTGBM :
        LightGBM sauvegarde les mod√®les en .txt (pas pickle).
        Avantages :
        - Lisible par l'humain (on peut voir les arbres)
        - Compatible entre versions de LightGBM
        - Taille r√©duite
        
        FORMAT M√âTRIQUES :
        JSON pour facilit√© de lecture et interop√©rabilit√©.
        Peut √™tre lu par n'importe quel langage.
        """
        # Sauvegarder le mod√®le
        model_path = os.path.join(self.model_dir, 'lightgbm_model.txt')
        self.model.save_model(model_path)
        logger.info(f"Model saved to {model_path}")
        
        # Sauvegarder les m√©triques
        metrics_path = os.path.join(self.model_dir, 'metrics.json')
        with open(metrics_path, 'w') as f:
            json.dump(self.metrics, f, indent=2)
        logger.info(f"Metrics saved to {metrics_path}")


# ============================================================================
# FONCTION PRINCIPALE
# ============================================================================

def main():
    """
    Pipeline principal d'entra√Ænement.
    
    WORKFLOW COMPLET :
    1. Charger les donn√©es pr√©trait√©es (engineered_features.csv)
    2. Initialiser le ModelTrainer
    3. Split train/test chronologique
    4. Entra√Æner le mod√®le (avec SMOTE l√©ger)
    5. √âvaluer sur le test set
    6. Sauvegarder mod√®le + m√©triques
    
    FICHIER D'ENTR√âE :
    data/processed/engineered_features.csv
    (G√©n√©r√© par un script de feature engineering)
    
    FICHIERS DE SORTIE :
    - models/lightgbm_model.txt
    - models/metrics.json
    
    DUR√âE TYPIQUE : ~2 minutes
    """
    logger.info("=== TRAINING PIPELINE START ===")
    
    # === √âTAPE 1 : CHARGER LES DONN√âES ===
    df = pd.read_csv('data/processed/engineered_features.csv', parse_dates=['date'])
    logger.info(f"Loaded {len(df)} samples with {len(df.columns)} features")
    
    # === √âTAPE 2 : INITIALISER L'ENTRA√éNEUR ===
    trainer = ModelTrainer()
    
    # === √âTAPE 3 : SPLIT TRAIN/TEST ===
    train_df, test_df = trainer.prepare_stratified_split(df)
    
    # === √âTAPE 4 : ENTRA√éNER ===
    trainer.train(train_df)
    
    # === √âTAPE 5 : √âVALUER ===
    trainer.evaluate(test_df)
    
    # === √âTAPE 6 : SAUVEGARDER ===
    trainer.save()
    
    logger.info("=== TRAINING PIPELINE COMPLETE ===")


# ============================================================================
# POINT D'ENTR√âE
# ============================================================================

if __name__ == '__main__':
    """
    Point d'entr√©e quand on ex√©cute : python model_trainer.py
    
    PR√âREQUIS :
    - Fichier data/processed/engineered_features.csv existant
    - Biblioth√®ques install√©es (pip install -r requirements.txt)
    
    UTILISATION :
    python model_trainer.py
    
    SORTIE ATTENDUE :
    - Logs d'entra√Ænement dans la console
    - Mod√®le sauvegard√© dans models/lightgbm_model.txt
    - M√©triques sauvegard√©es dans models/metrics.json
    """
    main()


# ============================================================================
# NOTES P√âDAGOGIQUES POUR DATA SCIENTIST JUNIOR
# ============================================================================

"""
üìö CONCEPTS CL√âS √Ä RETENIR :

1. PROGRAMMATION ORIENT√âE OBJET (POO)
   -----------------------------------
   Ce module utilise une classe ModelTrainer au lieu de fonctions.
   
   Avantages :
   - Encapsulation : √âtat (model, metrics) + comportement (train, evaluate)
   - R√©utilisabilit√© : Facile de cr√©er plusieurs instances
   - Organisation : Code plus structur√©
   - Testabilit√© : Chaque m√©thode testable ind√©pendamment
   
   Comparaison :
   ‚ùå Fonctions : train(), evaluate(), save() ‚Üí √âtat global (pas propre)
   ‚úÖ Classe : trainer.train(), trainer.evaluate(), trainer.save() ‚Üí √âtat encapsul√©

2. SPLIT CHRONOLOGIQUE (VS AL√âATOIRE)
   -----------------------------------
   En s√©ries temporelles, TOUJOURS splitter chronologiquement.
   
   Pourquoi ?
   - On pr√©dit le FUTUR √† partir du PASS√â
   - Split al√©atoire = triche (voir des donn√©es futures)
   - Performances artificiellement gonfl√©es
   
   R√®gle d'or :
   Train = Pass√© (80% des donn√©es)
   Test = Futur (20% des donn√©es)

3. SMOTE - POURQUOI "L√âGER" ?
   ---------------------------
   SMOTE cr√©e des donn√©es synth√©tiques pour √©quilibrer les classes.
   
   Probl√®me : SMOTE trop agressif (50/50) :
   - Cr√©e trop de donn√©es artificielles
   - Dilue les patterns r√©els
   - Overfitting sur les donn√©es synth√©tiques
   - Inverse les corr√©lations (Guediawaye < Dakar-Plateau)
   
   Solution : SMOTE l√©ger (20% max) :
   - R√©duit le d√©s√©quilibre SANS tout inverser
   - Pr√©serve les corr√©lations r√©elles
   - Meilleure g√©n√©ralisation
   
   Analogie :
   SMOTE complet = Augmenter le volume √† fond (saturation)
   SMOTE l√©ger = Augmenter juste ce qu'il faut (√©quilibre)

4. PARAM√àTRES LIGHTGBM - GUIDE COMPLET
   ------------------------------------
   LightGBM a 100+ param√®tres. Voici les plus importants :
   
   CONTR√îLE DE LA COMPLEXIT√â (√©viter overfitting) :
   - num_leaves : Nombre de feuilles par arbre (‚Üì = moins complexe)
   - max_depth : Profondeur des arbres (‚Üì = moins complexe)
   - min_child_samples : Min √©chantillons par feuille (‚Üë = plus robuste)
   - min_split_gain : Gain min pour un split (‚Üë = moins de splits)
   
   R√âGULARISATION :
   - reg_alpha : L1 regularization (Lasso, p√©nalise poids √©lev√©s)
   - reg_lambda : L2 regularization (Ridge, lisse les poids)
   
   SAMPLING :
   - feature_fraction : % de features par arbre (‚Üì = plus diverse)
   - bagging_fraction : % de donn√©es par arbre (‚Üì = plus diverse)
   
   APPRENTISSAGE :
   - learning_rate : Taux d'apprentissage (‚Üì = plus lent mais pr√©cis)
   - n_estimators : Nombre d'arbres (early stopping contr√¥le)
   
   D√âS√âQUILIBRE :
   - scale_pos_weight : Poids de la classe positive (‚Üë si tr√®s d√©s√©quilibr√©)

5. EARLY STOPPING
   ---------------
   M√©canisme qui arr√™te l'entra√Ænement automatiquement.
   
   Comment √ßa marche ?
   - Surveille une m√©trique sur validation set
   - Si pas d'am√©lioration pendant N it√©rations (patience)
   - ‚Üí Arr√™te l'entra√Ænement et garde le meilleur mod√®le
   
   Avantages :
   - √âvite l'overfitting (arr√™te avant que le mod√®le m√©morise)
   - √âconomise du temps (pas besoin de faire 1000 it√©rations)
   - Trouve le nombre optimal d'arbres automatiquement
   
   Dans notre code :
   lgb.early_stopping(stopping_rounds=50)
   ‚Üí Arr√™te si pas d'am√©lioration pendant 50 it√©rations

6. IMPORTANCE DES FEATURES
   ------------------------
   Mesure de l'utilit√© de chaque feature pour le mod√®le.
   
   Deux types :
   - 'gain' : Am√©lioration de la perte apport√©e par la feature (utilis√© ici)
   - 'split' : Nombre de fois que la feature est utilis√©e
   
   Utilit√© :
   - Comprendre quelles features sont importantes
   - Feature selection (supprimer les inutiles)
   - Interpr√©tabilit√© (expliquer les pr√©dictions)
   - Debugging (d√©tecter features trop dominantes)
   
   Exemple d'analyse :
   Si "quartier_encoded" a 80% d'importance :
   ‚Üí Probl√®me ! Le mod√®le se base trop sur le quartier
   ‚Üí Ajuster les param√®tres (max_depth, r√©gularisation)

7. M√âTRIQUES D'√âVALUATION - GUIDE COMPLET
   ---------------------------------------
   Chaque m√©trique r√©v√®le un aspect diff√©rent du mod√®le.
   
   ACCURACY (Exactitude) :
   - Formule : (TP + TN) / Total
   - Signification : % de pr√©dictions correctes
   - ‚ö†Ô∏è PI√àGE : Trompeuse sur donn√©es d√©s√©quilibr√©es
   - Exemple : 93% accuracy si on pr√©dit toujours "pas de coupure" (93% de 0)
   
   PRECISION (Pr√©cision) :
   - Formule : TP / (TP + FP)
   - Signification : % de vraies coupures parmi les pr√©dictions de coupure
   - Usage : Minimiser les fausses alertes
   - Question : "Parmi toutes mes alertes, combien sont vraies ?"
   
   RECALL (Rappel / Sensibilit√©) :
   - Formule : TP / (TP + FN)
   - Signification : % de coupures r√©elles d√©tect√©es
   - Usage : Ne rater aucune coupure
   - Question : "Parmi toutes les coupures, combien ai-je d√©tect√©es ?"
   
   F1-SCORE :
   - Formule : 2 √ó (Precision √ó Recall) / (Precision + Recall)
   - Signification : Moyenne harmonique de Precision et Recall
   - Usage : √âquilibre entre Precision et Recall
   - C'est LA m√©trique pour donn√©es d√©s√©quilibr√©es
   
   ROC-AUC (Area Under ROC Curve) :
   - Valeur : 0.5 (al√©atoire) √† 1.0 (parfait)
   - Signification : Capacit√© √† discriminer les classes
   - Usage : Comparer diff√©rents mod√®les
   - Ind√©pendant du seuil de d√©cision
   
   CONFUSION MATRIX :
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ            ‚îÇ Pr√©dit 0 ‚îÇ Pr√©dit 1 ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ R√©el 0     ‚îÇ    TN    ‚îÇ    FP    ‚îÇ
   ‚îÇ R√©el 1     ‚îÇ    FN    ‚îÇ    TP    ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   
   - TN (True Negative) : Pas de coupure, correctement pr√©dit ‚úÖ
   - FP (False Positive) : Fausse alerte üòê
   - FN (False Negative) : Coupure rat√©e ‚ùå (LE PIRE)
   - TP (True Positive) : Coupure d√©tect√©e ‚úÖ‚úÖ

8. TRADE-OFF PRECISION VS RECALL
   ------------------------------
   On ne peut pas maximiser les deux en m√™me temps.
   
   Seuil bas (ex: 0.1) :
   - Recall √©lev√© (d√©tecte presque toutes les coupures)
   - Precision faible (beaucoup de fausses alertes)
   
   Seuil √©lev√© (ex: 0.9) :
   - Precision √©lev√©e (peu de fausses alertes)
   - Recall faible (rate des coupures)
   
   Seuil optimal (ex: 0.5) :
   - F1-Score maximal (compromis)
   
   Choix selon le m√©tier :
   - M√©dical (cancer) : Recall √©lev√© (ne rater aucun cas)
   - Spam : Precision √©lev√©e (ne pas bloquer vrais emails)
   - Notre cas : F1 √©quilibr√© (ni trop d'alertes ni trop de rat√©s)

9. LOGGING VS PRINT
   -----------------
   Ce module utilise logging au lieu de print().
   
   Avantages du logging :
   - Niveaux de s√©v√©rit√© (DEBUG, INFO, WARNING, ERROR, CRITICAL)
   - Timestamps automatiques
   - Filtrage facile (afficher que les ERROR)
   - Sauvegarde dans fichiers
   - Configuration centralis√©e
   
   Exemple :
   ```python
   # ‚ùå MAUVAIS
   print("Training started")
   
   # ‚úÖ BON
   logger.info("Training started")
   ```
   
   Configuration :
   ```python
   logging.basicConfig(
       level=logging.INFO,           # Niveau minimum
       format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
       handlers=[
           logging.FileHandler('train.log'),  # Fichier
           logging.StreamHandler()            # Console
       ]
   )
   ```

10. TYPE HINTS (ANNOTATIONS DE TYPES)
    ----------------------------------
    Ce module utilise des annotations de types (Python 3.5+).
    
    Exemple :
    ```python
    def train(self, train_df: pd.DataFrame) -> Dict:
        ...
    ```
    
    Signification :
    - train_df: pd.DataFrame ‚Üí Param√®tre doit √™tre un DataFrame
    - -> Dict ‚Üí Fonction retourne un dictionnaire
    
    Avantages :
    - Documentation automatique (on voit les types attendus)
    - D√©tection d'erreurs (IDE signale les types incorrects)
    - Meilleure autocompl√©tion
    - Code plus lisible
    
    Types courants :
    - int, float, str, bool ‚Üí Types simples
    - List[int] ‚Üí Liste d'entiers
    - Dict[str, float] ‚Üí Dict avec cl√©s str, valeurs float
    - Tuple[int, int] ‚Üí Tuple de 2 entiers
    - Optional[str] ‚Üí Peut √™tre str ou None

11. PATTERN TEMPLATE METHOD
    ------------------------
    La classe ModelTrainer suit ce pattern de conception.
    
    Principe :
    - D√©finir le squelette d'un algorithme dans une m√©thode
    - D√©l√©guer certaines √©tapes √† des sous-m√©thodes
    - L'ordre est fixe, les d√©tails flexibles
    
    Dans notre cas :
    main() d√©finit le workflow :
    1. Load data
    2. Split train/test (prepare_stratified_split)
    3. Train (train)
    4. Evaluate (evaluate)
    5. Save (save)
    
    Avantages :
    - Structure claire et pr√©visible
    - Facile de modifier une √©tape sans casser le reste
    - Testable √©tape par √©tape
    
    Variante possible :
    On pourrait cr√©er une classe abstraite avec ces m√©thodes,
    et des classes enfants (RandomForestTrainer, XGBoostTrainer, etc.)

12. GESTION DES ERREURS (ROBUSTESSE)
    ---------------------------------
    Ce module pourrait √™tre am√©lior√© avec try/except.
    
    Points √† prot√©ger :
    - Chargement du CSV (fichier manquant, corrompu)
    - Entra√Ænement (OOM, interruption)
    - Sauvegarde (disque plein, permissions)
    
    Exemple de version robuste :
    ```python
    def save(self):
        try:
            model_path = os.path.join(self.model_dir, 'lightgbm_model.txt')
            self.model.save_model(model_path)
            logger.info(f"Model saved to {model_path}")
        except OSError as e:
            logger.error(f"Failed to save model: {e}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            raise
    ```

13. VERSIONING DES MOD√àLES
    -----------------------
    En production, il faut versionner les mod√®les.
    
    Strat√©gies :
    
    Approche 1 : Timestamp dans le nom
    ```python
    model_path = f'models/lgbm_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
    ```
    
    Approche 2 : Git pour les mod√®les
    - Git LFS (Large File Storage)
    - DVC (Data Version Control)
    
    Approche 3 : MLflow
    - Tracking des exp√©riences
    - Registry de mod√®les
    - Comparaison automatique
    
    Approche 4 : Dossiers num√©rot√©s
    ```
    models/
    ‚îú‚îÄ‚îÄ v1/
    ‚îÇ   ‚îú‚îÄ‚îÄ model.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
    ‚îú‚îÄ‚îÄ v2/
    ‚îÇ   ‚îú‚îÄ‚îÄ model.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
    ‚îî‚îÄ‚îÄ v3/ (current)
    ```

14. REPRODUCTIBILIT√â
    -----------------
    Ce module est reproductible gr√¢ce √† :
    
    1. random_state=42 partout
    2. Sort chronologique (pas d'al√©atoire)
    3. SMOTE avec random_state
    4. LightGBM avec random_state
    
    Pourquoi c'est important ?
    - Debugging : M√™me r√©sultats = m√™me bug
    - Collaboration : √âquipe voit les m√™mes r√©sultats
    - Validation : Prouver que les r√©sultats sont solides
    - Recherche : Papiers reproductibles
    
    Checklist reproductibilit√© :
    ‚úÖ random_state fix√©
    ‚úÖ Pas de shuffle al√©atoire
    ‚úÖ Versions des librairies fix√©es (requirements.txt)
    ‚úÖ Code versionn√© (Git)
    ‚úÖ Documentation compl√®te

15. OPTIMISATION FUTURE
    --------------------
    Am√©liorations possibles de ce module :
    
    A. Hyperparameter Tuning
       - Optuna, GridSearchCV, RandomSearchCV
       - Trouver les meilleurs param√®tres automatiquement
    
    B. Cross-Validation
       - K-fold validation (k=5)
       - Time series split (respecting chronology)
       - Plus robuste que single split
    
    C. Feature Engineering automatique
       - Featuretools, tsfresh
       - Polynomiale features
       - Interactions automatiques
    
    D. Ensemble Methods
       - Stacking (LightGBM + XGBoost + RF)
       - Voting classifier
       - Am√©liore performances de 1-3%
    
    E. Calibration des probabilit√©s
       - Platt scaling, Isotonic regression
       - Probabilit√©s plus fiables
    
    F. Monitoring en production
       - Data drift detection
       - Model drift detection
       - Alertes automatiques
    
    G. Explainability
       - SHAP values
       - LIME
       - Feature importance locale

16. COMMANDES UTILES
    -----------------
    # Entra√Æner le mod√®le
    python model_trainer.py
    
    # Voir les logs en temps r√©el
    tail -f train.log
    
    # V√©rifier le mod√®le sauvegard√©
    ls -lh models/
    
    # Visualiser les m√©triques
    cat models/metrics.json | python -m json.tool
    
    # Charger le mod√®le en Python
    import lightgbm as lgb
    model = lgb.Booster(model_file='models/lightgbm_model.txt')
    
    # Comparer plusieurs versions
    diff models/v1/metrics.json models/v2/metrics.json

17. ERREURS COURANTES ET SOLUTIONS
    --------------------------------
    ‚ùå "FileNotFoundError: engineered_features.csv"
    ‚úÖ Lancer le script de feature engineering d'abord
    
    ‚ùå "MemoryError during SMOTE"
    ‚úÖ R√©duire target_ratio (ex: 0.15 au lieu de 0.2)
    
    ‚ùå "ValueError: Found array with 0 sample(s)"
    ‚úÖ V√©rifier que le CSV n'est pas vide
    
    ‚ùå "LightGBM: min_data_in_leaf must be at least 1"
    ‚úÖ R√©duire min_child_samples si dataset tr√®s petit
    
    ‚ùå Overfitting (train F1 >> test F1)
    ‚úÖ Augmenter r√©gularisation (reg_alpha, reg_lambda)
    ‚úÖ R√©duire max_depth
    ‚úÖ Augmenter min_child_samples
    
    ‚ùå Underfitting (train F1 et test F1 bas)
    ‚úÖ Augmenter n_estimators
    ‚úÖ R√©duire learning_rate
    ‚úÖ Augmenter max_depth (mais attention overfitting)
    
    ‚ùå "quartier" domine feature importance
    ‚úÖ Appliquer les corrections V2 (ce module les a d√©j√†)

18. CHECKLIST AVANT D√âPLOIEMENT
    ----------------------------
    Avant de mettre ce mod√®le en production :
    
    ‚úÖ F1-Score > 0.60 (seuil minimum)
    ‚úÖ Pas d'overfitting (train F1 ‚âà test F1 ¬± 5%)
    ‚úÖ Feature importance √©quilibr√©e (pas de dominance)
    ‚úÖ Confusion matrix acceptable (FN < 30%)
    ‚úÖ Test√© sur donn√©es out-of-sample
    ‚úÖ Temps d'inf√©rence < 100ms
    ‚úÖ Mod√®le versionn√© et track√©
    ‚úÖ Documentation compl√®te
    ‚úÖ Monitoring en place
    ‚úÖ Rollback strategy d√©finie
"""